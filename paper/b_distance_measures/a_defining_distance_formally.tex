\section{Defining Distance Formally}

Distance is one of the most fundamental and rigorously defined measures in mathematics. It quantifies the separation between two points in a space, forming the foundation for concepts in geometry, analysis, and machine learning. Unlike intensity, which lacks a universal mathematical definition, distance is formally characterized within the framework of metric spaces.

\subsection{Metric Spaces and Distance Functions}

A \textbf{metric space} is a set \( X \) equipped with a function \( d: X \times X \to \mathbb{R} \) that satisfies specific properties ensuring a consistent measure of separation. This function \( d(x, y) \), called a \textbf{metric}, must satisfy the following axioms for all \( x, y, z \in X \):

\begin{enumerate}
    \item \textbf{Non-negativity:} The distance between any two points is always non-negative:
    \[
    d(x, y) \geq 0.
    \]
    \item \textbf{Identity of Indiscernibles:} The distance between a point and itself is zero, and only identical points have zero distance:
    \[
    d(x, y) = 0 \iff x = y.
    \]
    \item \textbf{Symmetry:} The distance from \( x \) to \( y \) is the same as from \( y \) to \( x \):
    \[
    d(x, y) = d(y, x).
    \]
    \item \textbf{Triangle Inequality:} The direct distance between two points is never greater than the sum of distances through an intermediate point:
    \[
    d(x, z) \leq d(x, y) + d(y, z).
    \]
\end{enumerate}

These properties ensure that distance behaves predictably and enables various mathematical operations, such as clustering, nearest-neighbor searches, and decision boundary calculations.

\subsection{Common Distance Metrics}

Several distance metrics appear frequently across mathematics, data science, and machine learning:

\subsubsection{Euclidean Distance}
The \textbf{Euclidean distance} is the most familiar and intuitive metric, defined in \( \mathbb{R}^n \) as:

\[
d_{\text{Euclidean}}(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}.
\]

This metric corresponds to the straight-line distance between two points and is widely used in geometric reasoning and optimization problems.

\subsubsection{Manhattan Distance}
The \textbf{Manhattan distance} (or \( L_1 \)-norm) measures distance along coordinate axes:

\[
d_{\text{Manhattan}}(x, y) = \sum_{i=1}^{n} |x_i - y_i|.
\]

It is useful in settings where movement is constrained to grid-like structures, such as robotics or urban navigation.

\subsubsection{Mahalanobis Distance}
Unlike Euclidean distance, which assumes uniform feature scaling, the \textbf{Mahalanobis distance} accounts for correlations between variables:

\[
D_M(x, y) = \sqrt{(x - y)^T \Sigma^{-1} (x - y)},
\]

where \( \Sigma \) is the covariance matrix of the dataset. This metric is particularly useful for measuring distances in high-dimensional spaces where feature variances differ.

\subsubsection{Cosine Distance}
The \textbf{cosine distance} measures the angle between two vectors rather than their absolute separation:

\[
d_{\text{cosine}}(x, y) = 1 - \frac{x \cdot y}{\|x\| \|y\|}.
\]

It is commonly used in text analysis and information retrieval, where directionality is more meaningful than magnitude.

\subsubsection{Kullback-Leibler Divergence (KL-Divergence)}
In probability and information theory, the \textbf{KL-divergence} measures how one probability distribution \( P \) diverges from another reference distribution \( Q \):

\[
D_{\text{KL}}(P || Q) = \sum_i P(i) \log \frac{P(i)}{Q(i)}.
\]

Unlike the previous metrics, KL-divergence is not symmetric and does not satisfy the triangle inequality, meaning it is not a true metric. However, it remains a useful measure of dissimilarity in probabilistic models.

\subsection{Distance as the Fundamental Measure}

A key property of distance measures is their universality: almost all similarity measures can be derived from distance functions, either through negation or transformation. In particular, \textbf{intensity measures often emerge as functions of distance}, a theme that will be explored in subsequent sections.

While distance is rigorously defined and essential in numerous mathematical formulations, intensity lacks a similar foundation. The next section will demonstrate why intensity must be interpreted as a function of relative distances rather than an independent measure.

